[
{
    "title": "Статистическая гипотеза: определение и примеры",
    "text": "**Статистической гипотезой** называется любое предположение о виде неизвестного распределения или о параметрах известных распределений.\n\nПримеры статистических гипотез:\n1. Генеральная совокупность распределена по закону Пуассона.\n2. Дисперсия генеральной совокупности равна 4 (при нормальном распределении).\n3. Математическое ожидание двух нормально распределённых генеральных совокупностей равны."
},
  {
    "title": "Параметрические и непараметрические гипотезы",
    "text": "**Параметрическая гипотеза** — содержит предположение о параметрах распределения случайной величины (при известном законе распределения).\n\n**Непараметрическая гипотеза** — все остальные случаи."
  },
  {
    "title": "Нулевая и альтернативная гипотезы",
    "text": "- **Нулевая гипотеза (H₀)** — выдвинутая гипотеза (основная).\n- **Альтернативная гипотеза (H₁)** — противоречит H₀.\n\nЕсли H₀ отвергается, принимается H₁."
  },
  {
    "title": "Простая и сложная гипотезы",
    "text": "**Простая гипотеза** содержит одно предположение. Пример:\n- Для показательного распределения с параметром $\\lambda$: $H_0: \\lambda = 5$.\n\n**Сложная гипотеза** состоит из конечного/бесконечного числа простых гипотез.."
  },
  {
    "title": "Исходы статистической проверки гипотез",
    "text": "Возможные ситуации после проверки H₀:\n1. H₀ верна **и** принимается.\n2. H₀ верна, **но** отвергается (ошибка I рода).\n3. H₀ неверна **и** отвергается.\n4. H₀ неверна, **но** принимается (ошибка II рода)."
  },
  {
    "title": "Ошибки первого и второго рода",
    "text": "**Ошибка первого рода**: $H_0$ отвергается, хотя она верна. Вероятность — $\\alpha$ (уровень значимости).\n\n**Ошибка второго рода**: $H_0$ принимается, хотя она неверна. Вероятность — $\\beta$.\n\n**Мощность критерия**: вероятность отвергнуть неверную $H_0$: $1 - \\beta$."
  },
  {
    "title": "Наиболее мощный критерий",
    "text": "Критерий называется **наиболее мощным**, если среди всех критериев с заданным уровнем значимости $\\alpha$ он имеет максимальную мощность $1 - \\beta$."
  },
  {
    "title": "Статистический критерий",
    "text": "Для проверки $H_0$ используют специально подобранную случайную величину (**статистический критерий**), точное или приближённое распределение которой известно. По выборке вычисляют **наблюдаемое значение критерия** $K_{\\text{набл}}$."
  },
  {
    "title": "Критическая область и область принятия гипотезы",
    "text": "Множество значений критерия делится на:\n- **Критическую область**: значения, при которых $H_0$ отвергается,\n- **Область принятия гипотезы**: значения, при которых $H_0$ принимается.\n\nКритические точки разделяют эти области."
  },
  {
    "title": "Типы критических областей",
    "text": "1. **Правосторонняя**: $K > k_{\\text{кр}}$ ($k_{\\text{кр}} > 0$)\n2. **Левосторонняя**: $K < k_{\\text{кр}}$\n3. **Двусторонняя**: $K > k_{2\\text{кр}}$ **или** $K < k_{1\\text{кр}}$ ($k_{2\\text{кр}} > k_{1\\text{кр}}$).\nДля симметричных распределений: $|K| > k_{\\text{кр}}$."
  },
  {
    "title": "Нахождение критических точек",
    "text": "- **Правосторонняя**: $P(K > k_{\\text{кр}}) = \\alpha$\n- **Левосторонняя**: $P(K < k_{\\text{кр}}) = \\alpha$\n- **Двусторонняя**: $P(K < k_{1\\text{кр}}) + P(K > k_{2\\text{кр}}) = \\alpha$.\nДля симметричных распределений: $P(K < -k_{\\text{кр}}) = P(K > k_{\\text{кр}}) = \\frac{\\alpha}{2}$."
  },
  {
    "title": "Общая схема проверки гипотез",
    "text": "1. Формулировка $H_0$ и $H_1$\n2. Выбор уровня значимости $\\alpha$\n3. Выбор статистического критерия\n4. Определение критической области по таблицам\n5. Расчёт $K_{\\text{набл}}$\n6. Решение:\n   - $K_{\\text{набл}} \\in$ области принятия → $H_0$ принимается,\n   - $K_{\\text{набл}} \\in$ критической области → $H_0$ отвергается."
  },
  {
    "title": "Оптимальный критерий",
    "text": "Критерий с **наибольшей мощностью** при заданном $\\alpha$ строится с помощью **отношения правдоподобия**:\n$$\\Lambda = \\frac{L_0(\\theta)}{L_1(\\theta)},$$\nгде $L_0$ и $L_1$ — функции правдоподобия для $H_0$ и $H_1$ соответственно."
  },
  {
    "title": "Критерий отношения правдоподобия",
    "text": "Пусть случайная величина ξ непрерывна, и $f_0(x)$ и $f_1(x)$ — плотности её распределения при справедливости гипотез $H_0$ (нулевая) и $H_1$ (конкурирующая). Обозначим $L_0(x_1, \\dots, x_n)$ — функцию правдоподобия при $H_0$, и $L_1(x_1, \\dots, x_n)$ — при $H_1$. Отношение $\\frac{L_1}{L_0}$ (при $L_0 \\neq 0$) называют **отношением правдоподобия**.\n\n**Теорема**: Среди всех критериев, проверяющих простую гипотезу $H_0$ против $H_1$ при заданном $\\alpha$, наиболее мощным является критерий отношения правдоподобия. Критическая область имеет вид:\n$$S = \\left\\{x: \\frac{L_1(x_1, \\dots, x_n)}{L_0(x_1, \\dots, x_n)} > C \\right\\} = \\alpha,$$\nгде константа $C$ находится из уравнения:\n$$P_{H_0}\\left(\\frac{L_1}{L_0} > C\\right) = \\alpha.$$"
  },
  {
    "title": "Наиболее мощный критерий для нормального распределения",
    "text": "**Пример**: Пусть $\\xi \\sim N(a, \\sigma^2)$, где $a$ неизвестно, $\\sigma^2$ известно. Требуется построить критерий для проверки $H_0: a = a_0$ против $H_1: a = a_1$ ($a_1 > a_0$).\n\n**Решение**:\n1. Плотности при $H_0$ и $H_1$:\n$$f_0(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x - a_0)^2}{2\\sigma^2}},$$\n$$f_1(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x - a_1)^2}{2\\sigma^2}}.$$\n2. Функции правдоподобия:\n$$L_0 = \\left(\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right)^n e^{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n (x_i - a_0)^2},$$\n$$L_1 = \\left(\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right)^n e^{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n (x_i - a_1)^2}.$$\n3. Отношение правдоподобия после преобразований:\n$$\\frac{L_1}{L_0} = e^{\\frac{n(a_1 - a_0)}{2\\sigma^2}(2\\bar{x} - a_1 - a_0)}.$$\n4. Критическая область: $\\bar{x} > C_1$, где $C_1 = a_0 + \\frac{\\sigma}{\\sqrt{n}} u_\\alpha$, а $u_\\alpha$ находится из $\\Phi(u_\\alpha) = \\frac{1}{2} - \\alpha$.\n\n**Мощность критерия**:\n$$1 - \\beta = \\frac{1}{2} + \\Phi\\left(\\frac{a_1 - a_0}{\\sigma}\\sqrt{n} - u_\\alpha\\right).$$\n**Замечания**:\n1. Минимальный объём выборки для заданных $\\alpha$, $\\beta$:\n$$n = \\frac{(u_\\alpha + u_\\beta)^2 \\sigma^2}{(a_1 - a_0)^2}.$$\n2. Уменьшение $\\alpha$ увеличивает $\\beta$ при фиксированном $n$.\n3. В дискретном случае используются вероятности вместо плотностей."
  },
  {
    "title": "Проверка гипотезы о математическом ожидании при известной дисперсии (нормальное распределение)",
    "text": "Пусть $\\xi \\sim N(a, \\sigma^2)$, где $\\sigma^2$ известна. По выборке $x_1, \\dots, x_n$ вычислено выборочное среднее $\\bar{x}$. Требуется проверить гипотезу $H_0: a = a_0$ на уровне значимости $\\alpha$ против трёх видов альтернатив:\n1. $H_1: a \\neq a_0$\n2. $H_1: a > a_0$\n3. $H_1: a < a_0$\n\n**Критерий проверки**:\n$$u = \\frac{\\bar{x} - a_0}{\\sigma} \\sqrt{n},$$\nгде при справедливости $H_0$: $u \\sim N(0,1)$.\n\n**Случай 1 (двусторонняя гипотеза)**:\n- Критическая область: $|u_{\\text{набл}}| > u_{\\text{кр}}$\n- Критическая точка $u_{\\text{кр}}$ находится из:\n$$\\Phi(u_{\\text{кр}}) = \\frac{1 - \\alpha}{2}$$\n**Правило**:\n- $H_0$ отвергается, если $|u_{\\text{набл}}| > u_{\\text{кр}}$\n- $H_0$ принимается, если $|u_{\\text{набл}}| < u_{\\text{кр}}$\n\n**Случай 2 (правосторонняя гипотеза)**:\n- Критическая область: $u_{\\text{набл}} > u_{\\text{кр}}$\n- Критическая точка $u_{\\text{кр}}$ находится из:\n$$\\Phi(u_{\\text{кр}}) = \\frac{1}{2} - \\alpha$$\n**Правило**:\n- $H_0$ отвергается при $u_{\\text{набл}} > u_{\\text{кр}}$\n\n**Случай 3 (левосторонняя гипотеза)**:\n- Критическая область: $u_{\\text{набл}} < -u_{\\text{кр}}$\n- Критическая точка $u_{\\text{кр}}$ находится аналогично случаю 2, но берётся со знаком «−»:\n$$u_{\\text{кр}} = -u'_{\\text{кр}}, \\quad \\Phi(u'_{\\text{кр}}) = \\frac{1}{2} - \\alpha$$\n**Правило**:\n- $H_0$ отвергается при $u_{\\text{набл}} < -u_{\\text{кр}}$"
  },
  {
    "title": "Построение критических областей для нормального критерия",
    "text": "**Обоснование для двусторонней гипотезы**:\n- Из симметрии $N(0,1)$: $u_{\\text{лев.кр}} = -u_{\\text{пр.кр}}$\n- Вероятность в критической области:\n$$P(u < -u_{\\text{кр}}) + P(u > u_{\\text{кр}}) = \\alpha$$\n- Решение уравнения для $u_{\\text{кр}}$:\n$$\\Phi(u_{\\text{кр}}) = \\frac{1 - \\alpha}{2}$$\n\n**Обоснование для односторонних гипотез**:\n- Для $H_1: a > a_0$ (правосторонняя):\n$$P(u > u_{\\text{кр}}) = \\alpha \\implies \\Phi(u_{\\text{кр}}) = \\frac{1}{2} - \\alpha$$\n- Для $H_1: a < a_0$ (левосторонняя):\n$$P(u < -u_{\\text{кр}}) = \\alpha \\implies \\Phi(-u_{\\text{кр}}) = \\frac{1}{2} - \\alpha$$"
  },
  {
    "title": "Критерий Стьюдента для проверки гипотезы о математическом ожидании при неизвестной дисперсии",
    "text": "Пусть $\\xi \\sim N(a, \\sigma^2)$, где $\\sigma^2$ неизвестна. По выборке $x_1, \\dots, x_n$ на уровне значимости $\\alpha$ проверяется гипотеза $H_0: a = a_0$ против альтернатив:\n1. $H_1: a \\neq a_0$\n2. $H_1: a > a_0$\n3. $H_1: a < a_0$\n\n**Критерий проверки**:\n$$T = \\frac{\\bar{x} - a_0}{S} \\sqrt{n},$$\nгде $S$ — выборочное стандартное отклонение. При справедливости $H_0$ величина $T$ имеет распределение Стьюдента с $k = n - 1$ степенями свободы."
  },
  {
    "title": "Построение критических областей для T-критерия Стьюдента",
    "text": "**Случай 1 (двусторонняя гипотеза $H_1: a \\neq a_0$)**:\n- Критическая область: $|T_{\\text{набл}}| > t_{\\text{двуст.кр}}(\\alpha, k)$\n- Критическое значение $t_{\\text{двуст.кр}}$ находится по таблице распределения Стьюдента для уровня $\\alpha$ и $k = n - 1$ степеней свободы.\n\n**Случай 2 (правосторонняя гипотеза $H_1: a > a_0$)**:\n- Критическая область: $T_{\\text{набл}} > t_{\\text{кр.одност}}(\\alpha, k)$\n- Критическое значение $t_{\\text{кр.одност}}$ определяется для односторонней области по таблице Стьюдента.\n\n**Случай 3 (левосторонняя гипотеза $H_1: a < a_0$)**:\n- Критическая область: $T_{\\text{набл}} < -t_{\\text{кр.одност}}(\\alpha, k)$\n- Критическое значение берётся с обратным знаком: $-t_{\\text{кр.одност}}$.\n\n**Правила принятия решений**:\n- $H_0$ отвергается, если $T_{\\text{набл}}$ попадает в критическую область.\n- $H_0$ принимается в противном случае."
  },
  {
    "title": "Критерий хи-квадрат для проверки гипотезы о дисперсии",
    "text": "Пусть $\\xi \\sim N(a, \\sigma^2)$, где $\\sigma^2$ неизвестна. По выборке $x_1, \\dots, x_n$ на уровне значимости $\\alpha$ проверяется гипотеза $H_0: \\sigma^2 = \\sigma_0^2$ против альтернатив:\n1. $H_1: \\sigma^2 \\neq \\sigma_0^2$\n2. $H_1: \\sigma^2 > \\sigma_0^2$\n3. $H_1: \\sigma^2 < \\sigma_0^2$\n\n**Критерий проверки**:\n$$\\chi^2 = \\frac{(n - 1) S^2}{\\sigma_0^2},$$\nгде $S^2$ — исправленная выборочная дисперсия. При справедливости $H_0$ величина $\\chi^2$ имеет распределение хи-квадрат с $k = n - 1$ степенями свободы."
  },
  {
    "title": "Построение критических областей для критерия хи-квадрат",
    "text": "**Случай 1 (двусторонняя гипотеза $H_1: \\sigma^2 \\neq \\sigma_0^2$)**:\n- Критические точки: $\\chi^2_{\\text{лев.кр}} = \\chi^2_{1 - \\alpha/2, n-1}$, $\\chi^2_{\\text{пр.кр}} = \\chi^2_{\\alpha/2, n-1}$\n- Критерий принятия решения:\n  - $H_0$ **принимается**, если $\\chi^2_{\\text{лев.кр}} < \\chi^2_{\\text{набл}} < \\chi^2_{\\text{пр.кр}}$\n  - $H_0$ **отвергается**, если $\\chi^2_{\\text{набл}} < \\chi^2_{\\text{лев.кр}}$ или $\\chi^2_{\\text{набл}} > \\chi^2_{\\text{пр.кр}}$\n\n**Случай 2 (правосторонняя гипотеза $H_1: \\sigma^2 > \\sigma_0^2$)**:\n- Критическая точка: $\\chi^2_{\\text{кр}} = \\chi^2_{\\alpha, n-1}$\n- Критерий принятия решения:\n  - $H_0$ **принимается**, если $\\chi^2_{\\text{набл}} < \\chi^2_{\\text{кр}}$\n  - $H_0$ **отвергается**, если $\\chi^2_{\\text{набл}} > \\chi^2_{\\text{кр}}$\n\n**Случай 3 (левосторонняя гипотеза $H_1: \\sigma^2 < \\sigma_0^2$)**:\n- Критическая точка: $\\chi^2_{\\text{кр}} = \\chi^2_{1 - \\alpha, n-1}$\n- Критерий принятия решения:\n  - $H_0$ **принимается**, если $\\chi^2_{\\text{набл}} > \\chi^2_{\\text{кр}}$\n  - $H_0$ **отвергается**, если $\\chi^2_{\\text{набл}} < \\chi^2_{\\text{кр}}$"
  },
  {
    "title": "Приближенный критерий для проверки гипотезы о вероятности успеха в схеме Бернулли",
    "text": "Пусть проводится проверка гипотезы $H_0: p = p_0$ (вероятность успеха) против альтернатив:\n1. $H_1: p \\neq p_0$\n2. $H_1: p > p_0$\n3. $H_1: p < p_0$\n\n**Условия применимости**:\n- Объём выборки $n$ достаточно велик ($n \\approx 100+$)\n- Выполнено: $n p_0 > 5$ и $n(1 - p_0) > 5$\n\n**Критерий проверки**:\n$$u = \\frac{w - p_0}{\\sqrt{\\frac{p_0(1 - p_0)}{n}}},$$\nгде $w = \\frac{\\text{число успехов}}{n}$ — относительная частота. При $H_0$: $u \\stackrel{\\text{асимпт.}}{\\sim} N(0,1)$."
  },
  {
    "title": "Построение критических областей для асимптотического нормального критерия",
    "text": "**Случай 1 (двусторонняя гипотеза $H_1: p \\neq p_0$)**:\n- Критическая область: $|u_{\\text{набл}}| > u_{\\text{кр}}$\n- Критическая точка $u_{\\text{кр}}$ находится из:\n$$\\Phi(u_{\\text{кр}}) = \\frac{1}{2} - \\frac{\\alpha}{2}$$\n**Правило**:\n- $H_0$ принимается, если $|u_{\\text{набл}}| < u_{\\text{кр}}$\n- $H_0$ отвергается в противном случае\n\n**Случай 2 (правосторонняя гипотеза $H_1: p > p_0$)**:\n- Критическая область: $u_{\\text{набл}} > u_{\\text{кр}}$\n- Критическая точка $u_{\\text{кр}}$ находится из:\n$$\\Phi(u_{\\text{кр}}) = \\frac{1}{2} - \\alpha$$\n**Правило**:\n- $H_0$ принимается при $u_{\\text{набл}} < u_{\\text{кр}}$\n\n**Случай 3 (левосторонняя гипотеза $H_1: p < p_0$)**:\n- Критическая область: $u_{\\text{набл}} < -u_{\\text{кр}}$\n- Критическая точка $-u_{\\text{кр}}$ находится из:\n$$\\Phi(u_{\\text{кр}}) = \\frac{1}{2} - \\alpha$$\n**Правило**:\n- $H_0$ принимается при $u_{\\text{набл}} > -u_{\\text{кр}}$"
  },
  {
    "title": "Критерий Стьюдента для зависимых выборок (парный t-критерий)",
    "text": "Пусть даны две зависимые выборки одинакового объёма $n$ из нормальных генеральных совокупностей $X \\sim N(a_x, \\sigma_x^2)$ и $Y \\sim N(a_y, \\sigma_y^2)$ с неизвестными дисперсиями. Для проверки гипотезы $H_0: a_x = a_y$ против альтернатив:\n1. $H_1: a_x \\neq a_y$\n2. $H_1: a_x > a_y$\n3. $H_1: a_x < a_y$\n\n**Методика проверки**:\n1. Вычислить разности $d_i = x_i - y_i$ для $i = 1, \\dots, n$\n2. Найти среднее разностей: $\\bar{d} = \\frac{1}{n}\\sum_{i=1}^n d_i$\n3. Вычислить исправленное стандартное отклонение разностей:\n$$S_d = \\sqrt{\\frac{1}{n-1}\\left(\\sum_{i=1}^n d_i^2 - \\frac{1}{n}\\left(\\sum_{i=1}^n d_i\\right)^2\\right)}$$\n4. Рассчитать наблюдаемое значение критерия:\n$$T_{\\text{набл}} = \\frac{\\bar{d}}{S_d} \\sqrt{n}$$\nПри $H_0$ статистика $T_{\\text{набл}}$ имеет распределение Стьюдента с $k = n - 1$ степенями свободы."
  },
  {
    "title": "Правила принятия решений для парного t-критерия",
    "text": "**Случай 1 (двусторонняя гипотеза $H_1: a_x \\neq a_y$)**:\n- Критическая область: $|T_{\\text{набл}}| > t_{\\text{двуст.кр}}(\\alpha, n-1)$\n- **Правило**:\n  - $H_0$ принимается, если $|T_{\\text{набл}}| < t_{\\text{двуст.кр}}$\n  - $H_0$ отвергается в противном случае\n\n**Случай 2 (правосторонняя гипотеза $H_1: a_x > a_y$)**:\n- Критическая область: $T_{\\text{набл}} > t_{\\text{кр.одност}}(\\alpha, n-1)$\n- **Правило**:\n  - $H_0$ принимается при $T_{\\text{набл}} < t_{\\text{кр.одност}}$\n  - $H_0$ отвергается в противном случае\n\n**Случай 3 (левосторонняя гипотеза $H_1: a_x < a_y$)**:\n- Критическая область: $T_{\\text{набл}} < -t_{\\text{кр.одност}}(\\alpha, n-1)$\n- **Правило**:\n  - $H_0$ принимается при $T_{\\text{набл}} > -t_{\\text{кр.одност}}$\n  - $H_0$ отвергается в противном случае\n\n**Примечание**: Критические значения $t_{\\text{двуст.кр}}$ и $t_{\\text{кр.одност}}$ берутся из таблицы распределения Стьюдента для уровня значимости $\\alpha$ и $k = n - 1$ степеней свободы."
  }
]